# ここ最近考えたこと (2024/06/11)

## 1. 縦方向の変形を含む一般化アースムーバー距離

3/15の [ISNSM2024](https://www.sat.t.u-tokyo.ac.jp/moonshot/ISNSM2024/) で甘利先生がWasserstein距離についてお話しされていました。その中で、Wasserstein距離は1次元分布でいうと横方向の変形であり、一方Kullback-Leiblerダイバージェンス (以下、KLダイバージェンス) は縦方向の違いを表すものだという見方を紹介されていました。また、私の理解が正しければ、Wasserstein距離は分布の形状の違いを捉えるのに有効と考えられることや、将来的にWasserstein距離とKLダイバージェンスを融合したいとお考えであることも話されていたと思います。

Wasserstein距離の定義式は連続分布を想定しているため難解ですが、離散分布向けのアースムーバー距離の定義式は比較的簡単です。そこで以下はアースムーバー距離について考えます。

アースムーバー距離は [Oku (2020)](http://id.nii.ac.jp/1001/00203781/) で用いた経験があります (スライドは[こちら](https://speakerdeck.com/okumakito/oku-slide-20200313))。この研究の時に、2次元の場合は最適輸送を線型計画法で解く必要がある一方、1次元の場合は単に比較したい2つの確率分布のそれぞれの累積分布の差の面積を計算すれば良いことを知りました。また、[Oku (2023a)](http://id.nii.ac.jp/1001/00229418/) で提案したクラリネットプロット (スライドは[こちら](https://speakerdeck.com/okumakito/oku-slide-20231129)) では累積分布の逆関数である分位関数を使うのですが、それが高周波成分の違いを反映しにくいことに気付いていました。おそらく積分操作が原因と考えています。

なので、横方向の変形に基づくアースムーバー距離に縦方向の変形を加えると、高周波成分の寄与が増えるのではないかと考えました。実際に、逆位相の2つのRademacher関数を考えてみると、縦方向の総変形量は周波数に依存しないのに対し、横方向の総変形量は周波数が高いほど小さくなることが確認できます。

取り敢えず [適当に考えた計算式](https://okumakito.github.io/20240322/memo.html) を書いてみたのですが、もっとちゃんとした式が [Pele and Werman (2009)](https://doi.org/10.1109/ICCV.2009.5459199) で既に発表済みであることに後から気づきました。しかも過去に読んだことがある論文でした。簡単に要点を述べると、縦横両方の変形を許容した最適化問題にした場合、横が有利なら横、縦が有利なら縦が選択されるため、地面距離がある値以上なら全て縦変形、そうでなければ横変形になるという話です。実装上は全ての点との地面距離が一定のダミー頂点を一つ加えるだけで済みます。この論文自体は既に1000回以上引用されているのですが、甘利先生がおっしゃっていた融合とはどうも違うような気がしています。

未病研究との関連について書いておきます。そもそも4年前にアースムーバー距離を扱ったのは、フローサイトメトリーやマスサイトメトリー (登録商標でいうとFACSとCyTOF) のデータから早期警戒信号を検出するためでした。定常分布が正規分布の場合は標準偏差や共分散行列の最大固有値 ([Oku and Aihara (2018)](https://doi.org/10.1587/nolta.9.166)) が有用です。また、外れ値がある場合は 中央絶対偏差 ([Oku (2019a)](https://doi.org/10.2197/ipsjtbio.12.9)) やロバスト化したデータ行列 ([Oku (2019b)](http://id.nii.ac.jp/1001/00194900/)) の共分散行列の最大固有値も有用です。しかし、変な形をした分布の場合、その形状が正常時と比べてどう異常なのかを示す方法が必要でした。そこでアースムーバー距離に着目した訳です。形の異常の検出法として汎用性があるため、scRNA-seqやsnRNA-seqのt-SNEやUMAPの図に対しても使えるだろうと考えています。

## 2. 累積距離検定

ふと、Wasserstein距離やアースムーバー距離は編集距離の一種と考えられるのではないかと思いました。だとすれば、神経科学のスパイク時系列解析の研究で使う編集距離の知見が応用できるのではないかと考えました。具体的に、[Victor and Purpura (1996)](https://doi.org/10.1152/jn.1996.76.2.1310) と [Iwayama, Hirata, Aihara (2017)](https://doi.org/10.1016/j.physleta.2016.10.061) が思い浮かびました。前者は、2つの点過程の比較において、移動、挿入、削除の3種類の編集を考えます。確率分布間の変形に置き換えると、移動が横方向の変形、挿入と削除が縦方向の変形に相当すると考えられます。縦方向変形の導入については前述した通りです。一方、後者で提案された累積距離では、比較したい2つの点過程に対して2方向の累積分布を考え、それぞれの差の2乗の積分を計算します。正確には、元論文ではマーク付き点過程に対する一般化した式が書いてあるのですが、ここではマーク無し点過程の場合のみを考えます。その場合、[かなり簡単な式](https://okumakito.github.io/20170427/memo.html) になります。計算も高速です。

さて、1次元分布の場合アースムーバー距離は2つの累積分布の差の面積に相当します。一方、2標本のKolmogorov-Smirnov検定 (以下、KS検定) では2つの累積分布の差の絶対値の上限を使います。さらに、累積距離は2つの累積分布の差の2乗の積分に基づいて計算されます。当然、どれが良いかが気になる訳です。

数値計算で調べてみたところ、累積距離を用いる [累積距離検定](https://okumakito.github.io/20240507/memo.html) は、分布の位置、尺度、形状の全ての変化に対してKS検定より高い検出力を持つ傾向が見られました。2つの累積分布の差が上限となる箇所以外の情報も含んでいるためと考えられます。

しかし、KS検定はそもそも検出力が極めて低いため、他の検定との比較も必要です。また、累積距離検定では検定統計量が従う標本分布が解析関数を用いて書けないと思われたため、並び替え検定を使いました。調べてみると、並び替え検定自体の問題点もあるようです。特に、帰無仮説が正しい場合の誤検出の確率が有意水準&alpha; (通常は0.05) を大幅に越える場合があるそうです。なので、累積距離検定でその問題が発生していないかを確認する必要もあります。

古典統計学ではFP (false positive) とFN (false negative) を非対称に考えます。最適化問題として捉えると、P(FP) &leq; &alpha; という制約条件の下で P(FN) を最小化するという発想です。なので、P(FP) &gt; &alpha; だと制約違反となるのです。

もし有用性が確認できれば、累積距離検定が2標本KS検定の上位互換になると思います。未病研究に限らず、幅広く様々な研究に役立つと思います。

一応、1標本の場合も調べました。正規分布に対する適合度検定で試したところ、残念ながら1標本累積距離検定はShapiro-Wilk検定に負けました。原因を調べているところです。

## 3. 確率分布の変形過程のスナップショット

アースムーバー距離を使った [Oku (2020)](http://id.nii.ac.jp/1001/00203781/) では、単に総変形量の値を計算するだけでなく、変形の様子をベクトル場で表しました ([発表スライドの26ページ目](https://speakerdeck.com/okumakito/oku-slide-20200313?slide=26))。ただし、定常流ではなく、各点のベクトルは変形の過程全体でその点を通過する量と向きの平均ベクトルです。また、発表の最後に変形の過程を動画でも示しました。しかし、その様子がアメーバのようで少し気持ち悪かったのです。近距離の移動がすぐ終わる一方、遠距離の移動に時間がかかっていたため、アメーバがじわじわ伸びているように見えたのだと考えています。この発表で大変光栄なことにSIGBIO優秀プレゼンテーション賞と [山下記念研究賞](https://www.ipsj.or.jp/award/yamasita2020-detail.html#bio) を頂いたのですが、個人的にはこの部分に納得出来ていませんでした。

そこで、変形過程の動画や一定時間毎のスナップショットが綺麗に見えるよう、移動距離によらず開始時点と終了時点を揃えたいと考えました。未病研究としても、早期警戒信号として分布の形に何らかの異常が生じたとき、正常状態と比べてどう変化したかを分かりやすく表示する手法は役に立つと考えられます。

1次元は簡単でした。比較したい2つの確率分布のそれぞれの累積分布を作り、分位数の等しい点同士を対応させて、それを初期状態から終了状態まで線形に動かすだけで済みます。例えば、分布Aの50%点を分布Bの50%点に向かって動かし、分布Aの25%点を分布Bの25%点に向かって動かす、といった感じです。各時点の累積分布の差分を取ることで各時点の確率分布が得られます。数値計算の結果、分布の平行移動、分散の変化、山の分裂や融合を自然に表すことが出来ました。

2次元が厄介です。アースムーバー距離であれば最適輸送を線形計画法で解く必要があります。一方、1次元と同様に考えるなら、2次元の累積分布では分位数の等しい点が等高線をなすため、2つの累積分布の等高線同士を対応させる方が自然とも考えられます。実装上は、2次元格子状に配置した各点を、自身と分位数の等しい相手側の点で最も近い点へ対応させる方が数値誤差が少なくて済みます。

このように等分位点同士を最短距離で対応させる方式は一般にアースムーバー距離と異なります。例えば、分布Aが(0,0), (1,1+&epsilon;)を中心とする2つの山から成り、分布Bが(1,0), (0,1+&epsilon;)を中心とする2つの山から成るとします。ただし&epsilon;は小さい正の値とします。最適輸送では(0,0)の山を(1,0)へ動かし、(1,1+&epsilon;)の山を(0,1+&epsilon;)の山に動かします。一方、等分位点対応法では、それぞれの山がほぼ半分ずつに分かれて (1,0), (0,1+&epsilon;)に向かって動き、そこでもう一方から来た塊と合わさると予想されます。

実装はまだですが、確率分布間の変形を累積分布で考えることにより、場の局所的な拡大、縮小、歪みとして変形を表すことが出来るだろうと予想しています。分位点に着目したのはクラリネットプロットの研究 ([Oku (2023a)](http://id.nii.ac.jp/1001/00229418/)) をしていたため、場の変形を格子点の動きで表そうと考えたのはバブロイドアルゴリズムの研究 ([Oku (2019c)](https://doi.org/10.1109/IIAI-AAI.2019.00191)) をしていたためだと思います。過去の研究が色々と役に立っている気がします。

そもそもアースムーバー距離は計算時間がかかることが大きな問題でした。線形計画法は最適化手法の中では高速な部類ですが、アースムーバー距離を定義式どおりに計算しようとするとそこそこ時間がかかるのです。そのため多数の高速化手法が提案されてきました。私が [Oku (2020)](http://id.nii.ac.jp/1001/00203781/) で使ったのは [Ling and Okada (2007)](https://doi.org/10.1109/TPAMI.2007.1058) で提案されたEMD-L1をベースにした手法です。他にも幾つかの系統があります。等分位点対応法をアースムーバー距離の近似手法の一つとして紹介すると、そちらの分野の方に興味を持って貰えるかもしれません。

確率分布を想定していましたが、総和が1でない場合にも拡張可能です。各点を始点から終点へ向かって線形に動かすだけなので、総和も初期値から終了値に向かって線形に変えれば良いだけです。実装上は、一旦比較対象の2つの分布の総和が1となるように正規化し、そこで等分位点対応を計算し (正規化してあるので必ず対応付け可能)、各時点のスナップショットを計算する段階で総和を元のスケールに戻すのが良いだろうと考えています。あと、未病研究から離れるのでやりませんが、画像から画像へのモーフィングにも使えそうです。RGBやHSVで3枚に分ければ適用可能と思います。

## 4. エネルギー地形解析の拡張

エネルギー地形解析という用語は複数の意味で用いられます。ここでは [Ezaki, et al. (2017)](https://doi.org/10.1098/rsta.2016.0287) の意味で使います。元々 [江崎先生のMatlabのコード](https://github.com/tkEzaki/energy-landscape-analysis) が公開されていました。それを私が2023年6月に [Pythonに移植して公開](https://github.com/okumakito/elapy) しました。移植の際に [ダイクストラ法の亜種](https://qiita.com/okumakito/items/f8fbf808abad07fd952b) について勉強したり、ベースングラフの描画でMatlabに対応する関数が無かったため [頂点一様配置法](https://qiita.com/okumakito/items/902152a66d646f61d7ed) を自作したりしました。これを自分自身では漢方薬のデータに適用して学会発表 ([Oku (2023b)](https://speakerdeck.com/okumakito/oku-slide-20230827)) しました。また、富山大の未病研究センターの数理の先生方に紹介して、早速学会発表 (Ito, et al. 2023) や 論文 ([Yonezawa, et al. (2024)](https://doi.org/10.3390/ijms25031570)) で使って頂きました。現時点で投稿準備中の論文も1本あります。

こうしてエネルギー地形解析にある程度慣れ親しんできたところで、色々と拡張のアイデアが出てきました。以下にまとめます。ただし、私自身がこれらの研究に取り組むつもりはありません。同様のことは既に他の方々も思いついていると思いますし、私自身も他の案件で手一杯のためです。ご興味のある方は是非挑戦してみて下さい。

エネルギー地形解析の主な手順は以下のとおりです。この順に整理します。
1. 変数選択
2. 二値化
3. イジングモデルのパラメータを最尤法で計算
4. 遷移グラフの計算
5. ベースングラフ (basin graph) の計算
6. 非連結性グラフ (disconnectivity graph) の計算

### 変数選択

エネルギー地形解析では7個程度の変数を選ぶことが推奨されています。その主な理由は、変数の数を n としたときパターン数が 2<sup>n</sup> となり、変数を1つ増やすごとにパターン数が2倍に増え、計算時間が増加し、計算精度が低下し、結果の解釈が困難になるためと私は考えています。

7個の変数のそれぞれは複数の変数の混合でも構いません。例えば、元データが20変数だったとします。このとき、クラスタリングで変数を7クラスタに分け、各変数を標準化した上でクラスタ毎に平均すれば7変数になります。あるいは、主成分分析をかけて第7主成分までを変数としても良いでしょう。そもそも元論文ではfMRIの多数のvoxelをまとめたROI (region of interest) を単位としていました。

計算時間と計算精度については、イジングモデルの推定と遷移グラフの計算以降を分けて考える必要があります。イジングモデルの推定だけなら、変数の数 n に対してパラメータ数は約 n<sup>2</sup>/2 なので、計算時間も計算精度もさほど問題になりません。実際、私が漢方薬のデータに適用 ([Oku (2023b)](https://speakerdeck.com/okumakito/oku-slide-20230827)) した際は変数が100個以上でしたが、計算はすぐ終わり、イジングモデルの推定も問題なく出来ていました。一方、ベースングラフの計算では、可能な 2<sup>n</sup> 個の全てのパターンを計算対象とするのでなく、実際に観測されたパターンのみを計算対象とすることで、計算時間の増加と計算精度の低下を大幅に抑えることが出来ると思います。その場合、変数は7個よりずっと多くても大丈夫なはずです。


### 二値化

イジングモデルは二値確率ベクトルの同時分布を表現するモデルのため、イジングモデルを使う限りは二値化が必要です。多値化あるいは連続値化をするには別のモデルを使う必要があります。

医学分野への応用を考えると多値化が重要です。例えばBMIでいうと、25以上は太り過ぎ、18.5未満は痩せすぎ、18.5以上25未満が正常範囲なので、2値より3値の方が適しています。もちろん、より細かく分けることも可能です。数理科学者の発想としてはイジングモデルの拡張としてPottsモデルがまず思い浮かぶと思うのですが、Pottsモデルが実用的かどうかは試してみないと分かりません。Pottsモデルは私も学生時代に研究で使ったことがあります ([Oku and Aihara (2011a)](https://doi.org/10.1007/978-94-007-4792-0_29))。あるいは、1つの連続変数に複数の2値変数を割り当てることで多値を表現する方法も考えられます。2ビットなら4段階、3ビットなら8段階、8ビット (=1バイト) なら256段階を区別可能です。これは単に符号化の話で、計算上はそのままイジングモデルを使うことが出来ます。私自身の博士論文のメインテーマの研究 ([Oku and Aihara (2011b](https://doi.org/10.1587/nolta.2.508)) でも使っていた手法です。

連続値の場合はこの手順を飛ばします。ただし、高次元だと密度推定が難しくなるため、主成分分析などで2次元から多くとも10次元程度に次元削減しておくのが良いと思います。事前のPCAによる次元削減はscRNA-seq解析でt-SNEを計算する際も一般に行われている前処理です。

また、二値、多値、連続値のいずれとも異なる別の方法もあります。元手法における二値化を、データ空間が n 次元の実数全体だったとき、それを各軸毎に2分割して、空間全体を 2<sup>n</sup> 個の部分空間に分割することだと考えます。だとすれば、空間全体に k 個の代表点を配置し、各データ点を近傍の代表点に対応させても良いのではないかと考えられます。つまり、変数毎の二値化でなく状態空間全体の離散化です。代表点は、観測点からランダムに選択したり、クラスタリングをかけたときの各クラスタの重心にしたりすれば良いだろうと思います。

### イジングモデルのパラメータを最尤法で計算

イジングモデルの場合は [Ezaki, et al. (2017)](https://doi.org/10.1098/rsta.2016.0287) のとおり厳密解法または近似解法を使えば良いと思います。Pottsモデルの場合はイジングモデルと同様に勾配法で逐次更新すれば良いのではないかと思います。連続値の場合はカーネル密度推定やk近傍密度推定で格子点上での確率密度を推定するのが良いだろうと思います。k近傍密度推定の問題については後述します。一般の離散化の場合は各代表点に割り当てられるデータ点の割合をそのままその点における確率質量の推定値とすれば良いだろうと思います。

この手順の本質的な意味は確率質量推定または確率密度推定だと私は考えています。エネルギーという表現はあくまで比喩に過ぎず、本質的な目的は定常分布における各点の確率または確率密度をデータから推定することだと思います。経験分布をそのまま使うのでなく敢えてイジングモデルをフィッティングさせそこから再計算している理由は、通常の回帰モデルと同様に、そうした方がノイズに強くなるためだろうと考えています。

### 遷移グラフの計算

[Ezaki, et al. (2017)](https://doi.org/10.1098/rsta.2016.0287) ではハミング距離が1以下の範囲を近傍とし、近傍間のみを遷移可能とする遷移グラフを考えていました。これはボルツマンマシンでいうと非同期更新 (1ステップに1変数のみ更新) に対応します。一方、可能な全パターンでなく観測されたパターンのみを計算対象とする場合、遷移グラフを連結にするために遷移可能な範囲を広げる必要があります。ハミング距離の閾値を上げても良いですし、私が漢方薬のデータに適用 ([Oku (2023b)](https://speakerdeck.com/okumakito/oku-slide-20230827)) した際に使った手法のように、同期更新 (1ステップに全変数を更新) で相対的に遷移しやすい相手先への遷移を許可しても良いと思います。

多値や一般の離散化の場合はユークリッド距離を使うのが自然と思います。近傍範囲の最大距離を指定する方法と近傍数を指定する方法が考えられます。どちらが良いかは試してみないと分かりません。

連続値の場合は、実空間の指定範囲内に十分細かい間隔で格子点を配置し、それぞれが近傍同士で遷移可能として遷移グラフを作るのが良いと思います。頂点数が膨大になるため、それなりの計算用サーバを用意する必要があるだろうと思います。

### ベースングラフの計算

ベースングラフの計算は、全パターン使用の二値、観測パターンのみ使用の二値、多値、連続値、一般の離散化のいずれも同様だと思います。つまり、遷移グラフ上の各頂点から、自身と隣接頂点の中で推定確率密度/質量が一番高い頂点に向かって有向枝を張ることでベースングラフが得られます。ベースングラフの弱連結成分が状態です。各状態で確率が最大の頂点 (エネルギーが最小の頂点) をその状態の代表パターンとします。頂点数が多い場合はベースングラフを図示せず、各状態に属する頂点数と代表パターンだけ出力すれば良いと思います。

なお、エネルギー地形解析は力学系が勾配系であることと定常性を仮定しています。近傍範囲内で推定確率が最大の頂点に向かって最も動きやすいと仮定しているのはそのためです。非勾配系や非定常系であれば、ある点がどの方向に動きやすいかは、行き先の確率だけでは決まりません。その場合は、各パターンがどのパターンに遷移しやすいかの推定が必要と思います。その場合の制御理論との関係は後述します。

### 非連結性グラフの計算

これも元論文と同じです。

### 注意すべきこと

色々とアイデアを書いてみましたが、幾つか注意すべきことがあります。まず、既存のクラスタリング手法で済むことをやっても仕方ないということです。データ全体を複数のグループに分けるだけなら、わざわざエネルギー地形解析を使う必要はなく、K平均法や階層的クラスタリングで十分です。エネルギー地形解析を拡張した結果、元のエネルギー地形解析から離れていって、既存のクラスタリング手法の劣化版に行き着いてしまってはいけないのです。敢えて2値化を採用したことで生じていた独自性を捨てた場合、それに代わる何かがないといけません。

同様に、既存の次元削減で済むことをやっても仕方ありません。連続値エネルギー地形解析を2次元でやろうとすると、結局t-SNEやUMAPの図をカーネル密度推定してz軸方向を反転したような図になってしまう危険があります。それでは意味がありません。

## 5. パターンに基づく制御理論

これは以前 [HPのメモ](https://okumakito.github.io/20240322_2/memo.html) に書いた話です。エネルギー地形解析と同様に、多次元連続値の系の状態を離散点で表すことの利点について最近考えています。エネルギー地形解析は定常な勾配系を仮定しますが、ここではその仮定をしません。周期的な動きをしても構いませんし、Waddington地形のように一方向に流れてそこで終わってしまっても構いません。また、通常の層別化では人間が解釈しやすいよう2個から5個程度のグループに分けますが、ここでは100個以上の点を考えます。その意味でfine-scaleな層別化と考えても良いかもしれません。

重要なことは、通常の数理モデルでは各変数を頂点、変数間の相互作用を枝とするネットワークを考えるのに対し、ここでは多次元ベクトルの各状態を頂点、状態間の遷移を枝とする遷移グラフを考えることです。仮に前者をメカニズムベースのモデル、後者をパターンベースのモデルと呼ぶことします。メカニズムベースのモデルは現象の理解に有用ですが、正確な推定には膨大なデータを必要とします。一方、パターンベースのモデルでは実際に観測された遷移のパターンを考えるため、現象の理解には役立ちませんが推定が容易です。未病研究では人体という極めて複雑な系を対象とするため、メカニズムベースのモデルよりパターンベースのモデルの方が向いていると考えられます。

少し脱線すると、おそらく人間が世界を認知するやり方もおそらく両方あって、まずは個別のエピソード記憶の蓄積があり、それらが束ねられてパターンベースの内部モデルが形成され、それを説明可能な仮説が色々と作られて統合されメカニズムベースの内部モデルになるのではないかと思います。そして、両方のモデルは互いに影響を及ぼし合いながら随時更新されているのだろうと思います。直観的思考と論理的思考ともおおよそ対応すると思います。

遷移グラフ上のダイナミクスはマルコフ連鎖モデルで記述出来ます。個別の軌跡を考える代わりに確率分布自体の時間発展を考える場合、単体上の離散時間線形系 x(t+1)=A.x(t) となります。統計力学におけるLangevin方程式とFokker-Planck方程式の関係に似ています。個別の軌跡に対して制御入力を加える場合はマルコフ決定過程となり、一般に強化学習を使って最適方策を計算します。一方、確率分布の時間発展を表す線形系の場合は制御理論が適用可能なはずです。

3月23日にこの話を井村研の皆様にした際、離散事象システムや強化学習との関連を指摘頂きました。離散事象システムのことはよく分かっていませんが、人工システムを前提としたもののようで、生命を対象としてデータ駆動的に遷移グラフを作る状況とは大分違うように思います。一方、強化学習はまさに大きく関係していました (なのですぐ上でも言及しました)。強化学習では、各状態に報酬の値を設定し、期待報酬を最大化するような方策を計算します。一方、制御理論では、安定化したい目標状態を決め、それを安定化するようにシステム行列Aに変更を加えます。

ここでの安定状態とは、離散化したn点それぞれの存在確率を並べたn次元のベクトルです。確率なので総和は1です。遷移グラフ上の特定の一つの頂点に収束させるのではなく、どの状態の確率を高く保ち、どの状態の確率を低く抑えるか、という制御です。また、フィードバック制御を加えて行列Aの (i,j) 成分を変化させることは、状態jから状態iへの遷移を何らかの方法で抑制または促進することに対応します。つまり、ヒトの健康状態を100パターンなり1000パターンなりに区分けしたとき、特定のパターンになったときだけ介入をし、望ましくない健康パターンへの遷移を抑えたり、望ましいパターンへの回帰を促すことに対応します。介入方法としては、運動療法、食事療法、薬物療法などが考えられます。フィードバック入力を加えるA行列の要素をスパースにすれば、限られた健康状態での介入、すなわちJITAI (Just-in-time Adaptive Intervention) になります。

さらに、遷移グラフ上の制御理論を考えると、直観的には非自明な介入が理論上推奨される可能性があります。つまり、医師が見ても明らかに発症リスクが高そうだと思う健康パターンではなく、一見すると十分健康そうなパターンで介入が必要という計算結果が出る場合があるということです。これは遷移グラフ上のフローを考えたとき、流れが分岐する上流の位置に相当するはずです。ネットワーク制御というとメカニズムベースのモデルばかりイメージされてしまいますが、遷移グラフ上の上流を狙った最適介入という意味でのネットワーク制御も考えてみる価値があると思います。

階層制御も同じで、メカニズムベースのモデルにおける階層性だけでなく、粗視化の粒度を変えた複数の遷移グラフの間での階層性という観点も面白そうだと思います。

## 6. エネルギー地形解析の非連結性グラフ + 分枝埋め込み法

エネルギー地形解析という用語は2次元の地形図を連想させます。しかし、実際のエネルギー地形解析で出てくるのは味気ない樹形図であり、名前と解離しています。この問題に対して川上先生はベースングラフの全ての連結成分を円形領域内に一緒に詰め込んで地形図を作るというアプローチ [Kawakami (2020)](https://acmedsci.ac.uk/file-download/34621546) を提案されています。しかし、どういう訳か論文にはなっていないのです。私はずっと、本当は高次元空間上で定義されるエネルギー地形を2次元で表すとどうしても不正確になるため、有用性がなかなか認められないのではないかと勝手に考えていました。しかし、よく考えるとベースングラフでなく非連結性グラフの方は2次元平面に放射状に埋め込んでも正確性が損なわれないと気づきました。一般的にも、系統樹を一方向でなく放射状に展開させる表示法がよく使われています。樹形図から散布図への変換には昔作った分枝埋め込み法 ([Oku (2018b)](https://doi.org/10.48550/arXiv.1805.02161)) が使えると思います。ただし、枝は表示する必要があります。

ひとたび非連結性グラフを放射状に展開してしまえば、そこから地形図を作るのは簡単です。2次元平面上に格子点を配置し、各点でのエネルギーの高さを2次元に埋め込んだ非連結性グラフ上の近い点でのエネルギー値と近い値にすれば良いと思います。少し試したところ、i番目のエネルギー極小パターンまたは鞍点パターンのエネルギーを E<sub>i</sub>, 計算対象の点からそこまでの距離を d<sub>i</sub> として、重みを w<sub>i</sub>&propto;1/d<sub>i</sub>, &Sigma;w<sub>i</sub>=1 とし、重み付け和 &Sigma;w<sub>i</sub>E<sub>i</sub> を使えば良さそうな感じです。

## 7. ネットワークの頂点一様配置法

元々は [エネルギー地形解析のMatlabコード](https://github.com/tkEzaki/energy-landscape-analysis) の [Python移植版](https://github.com/okumakito/elapy) を作った際に作った [頂点一様配置法](https://qiita.com/okumakito/items/902152a66d646f61d7ed) ですが、それを [STRINGの結果の再描画関数](https://qiita.com/okumakito/items/b413cdc2ba3f9f22bcbf) に使った際に2つの変更を加えました。1つは描画領域として矩形と円形を選択できるようにしたことです。もう一つは頂点の色を [Estrada and Hatano (2008)](https://doi.org/10.1103/PhysRevE.77.036111) で提案されたCommunicabilityで計算したことです。座標が近い頂点同士が必ずしもネットワーク上で近いとは限らないため、色でネットワーク上の近さを表しました。

通常のPCA, MDS, t-SNE, UMAPなどの次元削減は、データ点の粗密により構造を示します。一方、頂点一様配置法は100頂点以下を目安に、全ての頂点のラベルが読めることを第一目標としたため、頂点の密度は一様です。そこで、頂点同士の元空間での類似度を色で表すという発想が出てきました。他にも、同じネットワークコミュニティを枠で囲んだり、頂点の形で区別したりすることも出来ると思います。いずれにせよ、他の次元削減とは異なる考え方のデータ可視化だと思います。

上記の頂点一様配置法では、初期状態をバネモデルで決め、以降は頂点間の斥力により逐次的に各頂点の位置を更新します。逐次更新の段階でネットワーク構造を考慮していないため、最終的にある頂点が他の2頂点を結ぶ枝の上に乗ってしまう場合がありました。この問題を解決するため、斥力を頂点間でなく頂点と枝の間にかけてみてはどうかと考えています。まだ試していません。

## 8. 同等性検定の基準設定法

統計学の講義では毎年、t検定でp&geq;0.05のとき差がないと主張してはいけないと教えています。あれはあくまで差があることを示すための手法であって、p&geq;0.05だと差あるかどうか分からないためです。差がないと主張したいのであれば、帰無仮説として差の絶対値が指定値以上であることを仮定し、それを否定することで差の絶対値が指定値未満であることを示すべきで、 同等性検定と呼ばれています。

この指定値の決め方として、50-95ルールを考えてみました。本当に差がなかった場合、各標本のサイズが50のときの検出力が95%となるように同等性の許容域を定めるという案です。n=10ずつではほとんど有意になることはなく、n=20ずつでようやく40%くらい、名前のとおりn=50ずつ揃えれば (本当に差がなかった場合) 95%の確率で同等性を示すことが出来ます。あまり素人が適当なことをいうものではないですが、このルールは他の検定にも応答出来るという利点があります。例えば、相関係数が0と同等であることを示したいとき、分布が正規分布と同等であることを示したいときなどにも使えると思います。

## 9. バブロイドアルゴリズムの地図表示

富山大学のシーズ集に [自身の研究紹介](https://sanren.ctg.u-toyama.ac.jp/seeds_search/search/detail/32) を書いた際、バブロイドアルゴリズム ([Oku (2019c)](https://doi.org/10.1109/IIAI-AAI.2019.00191)) の地図への適用例が少し分かりづらいと感じました。丸みを帯び過ぎていてどれが何県か分からないことが原因と考えられます。同じ会議論文で使った格子状の図形に対する面積指定をすれば、もう少し原型をととどめたまま各地域の面積を変化させられる可能性があります。未病研究ではないのでメモだけ。

## 10. バブロイドアルゴリズム + 分枝埋め込み法

ふと、分枝埋め込み法 ([Oku (2018b)](https://doi.org/10.48550/arXiv.1805.02161))とバブロイドアルゴリズム ([Oku (2019c)](https://doi.org/10.1109/IIAI-AAI.2019.00191)) を合わせられないかと思いました。分枝埋め込み法では面積を持たない点の分裂の繰り返しにより樹形図を散布図に変換します。一方、細胞分裂のイメージで、面積を持つ多角形領域を樹形図に対応させて繰り返し分裂させ、各分裂毎にバブロイドアルゴリズムで輪郭線を滑らかにしたり面積をなるべく一定に保つようにしたりすれば、最終的に2次元領域内を細胞のような多角形がほぼ一様に埋め尽くすconfluentな状態になるのではないかと思われます。[ネットワークの頂点一様配置](https://qiita.com/okumakito/items/902152a66d646f61d7ed)の樹形図版ともいえます。未病研究ではないのでメモだけ。

## 11. 局所的に非一様なk近傍密度推定

一般に密度推定にはカーネル密度推定が用いられます。一方、[Oku (2020)](http://id.nii.ac.jp/1001/00203781/) でフローサイトメトリーデータの2次元分布の密度推定を行った際、カーネル密度推定の代わりにk近傍密度推定を試しました。k近傍密度推定は計算が速い一方、データ点の全く存在しない領域で確率密度が実際よりかなり高く推定されてしまうという問題があることが分かりました。そのため結局発表ではカーネル密度推定を使った結果を示しました。

k近傍密度推定ではk近傍範囲内で一様分布を仮定します。これを非一様分布に変えれば改善するのではないかと考えています。

## 参考文献

- 奥 牧人: フローサイトメトリーデータ解析ための方向制限付きアースムーバー距離の効率的な計算法, 情処研報, 2020-BIO-61(8):1-6 (2020). http://id.nii.ac.jp/1001/00203781/
- 奥 牧人: クラリネットプロット：バイオリンプロットに代わるscRNA-seqデータのゼロ過剰分布の表示法, 情処研報, 2023-BIO-76(6):1-6 (2023). http://id.nii.ac.jp/1001/00229418/
- O. Pele, M. Werman: Fast and robust earth mover's distances, 2009 IEEE 12th International Conference on Computer Vision, 460-467 (2009). https://doi.org/10.1109/ICCV.2009.5459199
- M. Oku, K. Aihara: On the covariance matrix of the stationary distribution of a noisy dynamical system, NOLTA, 9(2):166-184 (2018). https://doi.org/10.1587/nolta.9.166
- M. Oku: Two novel methods for extracting synchronously fluctuated genes, IPSJ Trans. Bioinform., 12:9-16 (2019). https://doi.org/10.2197/ipsjtbio.12.9
- 奥 牧人: もう一つの主成分分析に基づく同期性揺らぎ遺伝子抽出法, 情処研報, 2019-BIO-57(2):1-6 (2019). http://id.nii.ac.jp/1001/00194900/
- J. D. Victor, K. P. Purpura: Nature and precision of temporal coding in visual cortex: a metric-space analysis, J. Neurophys., 76(2):1310-1326 (1996). https://doi.org/10.1152/jn.1996.76.2.1310
- K. Iwayama, Y. Hirata, K. Aihara: Definition of distance for nonlinear time series analysis of marked point process data, Phys. Lett. A, 381(4):257-262 (2017). https://doi.org/10.1016/j.physleta.2016.10.061
- M. Oku: Bubbloid algorithm: A simple method for generating bubble-like line drawings, Proc. IIAI-AAI'19, pp. 954-959 (2019). https://doi.org/10.1109/IIAI-AAI.2019.00191
- H. Ling, K. Okada: An efficient earth mover's distance algorithm for robust histogram comparison, IEEE Transactions on Pattern Analysis and Machine Intelligence, 29(5):840-853 (2007). https://doi.org/10.1109/TPAMI.2007.1058
- T. Ezaki, T. Watanabe, M. Ohzeki, N. Masuda: Energy landscape analysis of neuroimaging data, Phil. Trans. R. Soc. A, 375(2096):20160287 (2017).
- 奥 牧人: 漢方処方のエネルギー地形解析, 第40回 和漢医薬学会学術大会, 2023/08/27, 富山. https://speakerdeck.com/okumakito/oku-slide-20230827
- 伊藤 遼, 上田 肇一, 木村 巌, 奥 牧人, 春木 孝之, 永田 義毅, 山上 孝司, 戸邉 一之: エネルギー地形法を用いた健康診断データ解析, 2023年度 電気・情報関係学会北陸支部連合大会 (JHES2023), 2023/09/02, online.
- S. Yonezawa, T. Haruki, K. Koizumi, A. Taketani, Y. Oshima, M. Oku, A. Wada, T. Sato, N. Masuda, J. Tahara, N. Fujisawa, S. Koshiyama, M. Kadowaki, I. Kitajima, S. Saito: Establishing monoclonal gammopathy of undetermined significance as an independent pre-disease state of multiple myeloma using Raman spectroscopy, dynamical network biomarker theory, and energy landscape analysis, Int. J. Mol. Sci., 25(3):1570 (2024). https://doi.org/10.3390/ijms25031570
- M. Oku, K. Aihara: Traveling waves in locally connected chaotic neural networks and their phenomenological modeling, Proc. ICCN'11, pp. 213-219 (2011). https://doi.org/10.1007/978-94-007-4792-0_29
- M. Oku, K. Aihara: Associative dynamics of color images in a large-scale chaotic neural network, NOLTA, 2(4):508-521 (2011). https://doi.org/10.1587/nolta.2.508
- E. Kawakami: Understanding and predicting disease through AI and mathematical analysis of health and medical data, AMS-JSPS-AMED Joint Symposium on Data-Driven Health (2020). https://acmedsci.ac.uk/file-download/34621546
- M. Oku: Branching embedding: A heuristic dimensionality reduction algorithm based on hierarchical clustering, arXiv, 1805.02161 (2018). https://doi.org/10.48550/arXiv.1805.02161
- E. Estrada, N. Hatano: Communicability in complex networks, Phy. Rev. E, 77:036111 (2008). https://doi.org/10.1103/PhysRevE.77.036111
